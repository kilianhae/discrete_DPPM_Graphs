{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813205f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool.all as gt\n",
    "import logging\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from argparse import Namespace\n",
    "import networkx as nx\n",
    "\n",
    "from evaluation.stats import eval_torch_batch, adjs_to_graphs, eval_graph_list, eval_acc_sbm_graph\n",
    "from easydict import EasyDict as edict\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from evaluation.stats import eval_torch_batch, adjs_to_graphs, eval_graph_list\n",
    "from utils.arg_helper import mkdir, set_seed, load_data, graphs_to_tensor, load_model, parse_arguments, \\\n",
    "    get_config\n",
    "from utils.graph_utils import discretenoise, generate_mask, discretenoise_balanced_single, discretenoise_balanced, discretenoise_single_density, discretenoise_balanced_single_density\n",
    "from utils.loading_utils import get_mc_sampler, eval_sample_batch, prepare_test_model_train\n",
    "from utils.visual_utils import plot_graphs_list, plot_inter_graphs, plot_inter_graphs_list, plot_inter_graphs_j\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from evaluation.stats import eval_torch_batch\n",
    "\n",
    "from model.langevin_mc import LangevinMCSampler\n",
    "\n",
    "from utils.arg_helper import edict2dict, parse_arguments, get_config, process_config, set_seed_and_logger, load_data\n",
    "from utils.graph_utils import gen_list_of_data_single, generate_mask\n",
    "from utils.loading_utils import get_mc_sampler, get_score_model, eval_sample_batch\n",
    "from utils.visual_utils import plot_graphs_adj\n",
    "from model.ppgn import Powerful\n",
    "from matplotlib import pyplot as plt\n",
    "import wandb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bcffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sysout=sys.stdout\n",
    "\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "def enablePrint():\n",
    "    sys.stdout = sysout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3930b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "##function for printing the intermediate noiselevels to jupyter\n",
    "\n",
    "def plot_inter_graphs_jup(graphs,flags,title,save_dir,nr_to_analyze=0):\n",
    "    maxnodes=0\n",
    "    graphs_proces=[]\n",
    "    for g in graphs:\n",
    "        graphs_proces.append(nx.from_numpy_matrix(g[0]))\n",
    "\n",
    "    torch.set_printoptions(profile=\"full\")\n",
    "    figure = plt.figure(figsize=(25, 25))\n",
    "    max_num=len(graphs)\n",
    "    img_c = int(np.sqrt(max_num))\n",
    "    pos=nx.spring_layout(graphs_proces[-1])\n",
    "    for i, sigmalevel_adjs in enumerate(graphs_proces):\n",
    "        plt.figure(figsize=(25, 25))\n",
    "        nodes=flags.sum(-1)\n",
    "        G = sigmalevel_adjs.copy()\n",
    "        G.remove_nodes_from(list(nx.isolates(G)))\n",
    "        e = G.number_of_edges()\n",
    "        v = G.number_of_nodes()\n",
    "        l = nx.number_of_selfloops(G)\n",
    "        ax = plt.subplot(img_c+1, img_c+1, i+1)\n",
    "        title_str = f'fl={\"nrofnodes\"},no={i}'\n",
    "        nx.draw(G, pos, with_labels=False, **options)\n",
    "        ax.title.set_text(title_str)\n",
    "        plt.show()\n",
    "        \n",
    "    title=f'{title}-{nr_to_analyze}.pdf'\n",
    "    figure.suptitle(title)\n",
    "\n",
    "options = {\n",
    "    'node_size': 2,\n",
    "    'edge_color': 'black',\n",
    "    'linewidths': 1,\n",
    "    'width': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d149e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ppgn_simple(config,modellink,noise_num):\n",
    "    \n",
    "    device=sys.stdout\n",
    "    blockPrint()\n",
    "    \n",
    "    train_graph_list, test_graph_list = load_data(config, get_graph_list=True)\n",
    "    models = prepare_test_model_train(config,modellink)\n",
    "    max_node_number = config.dataset.max_node_num\n",
    "    test_batch_size = config.test.batch_size\n",
    "    test_batch_size = 1\n",
    "    \n",
    "    \n",
    "    def gen_init_data(batch_size):\n",
    "        rand_idx = np.random.randint(0, len(train_graph_list), batch_size)\n",
    "        graph_list = [train_graph_list[i] for i in rand_idx]\n",
    "        base_adjs, base_x = graphs_to_tensor(config, graph_list)\n",
    "        base_adjs, base_x = base_adjs.to(config.dev), base_x.to(config.dev)\n",
    "        node_flags = base_adjs.sum(-1).gt(1e-5).to(dtype=torch.float32)\n",
    "\n",
    "        ##create a matrix with p=1/2 elements at all positions Aij where i and j not masked by node_flagij=0:\n",
    "        bernoulli_adj = torch.zeros(batch_size, max_node_number, max_node_number).to(config.dev)\n",
    "        for k, matrix in enumerate(base_adjs):\n",
    "            for i,row in enumerate(matrix):\n",
    "                    for j,col in enumerate(row):\n",
    "                        if 1/2 < node_flags[k][i] and 1/2 < node_flags[k][j]:\n",
    "                            bernoulli_adj[k,i,j] = 1/2\n",
    "                        \n",
    "        noise_upper = torch.bernoulli(bernoulli_adj).triu(diagonal=1)\n",
    "        noise_lower = noise_upper.transpose(-1, -2)\n",
    "        initialmatrix = noise_lower + noise_upper\n",
    "        return initialmatrix, base_x, node_flags\n",
    "        ##returns initialmatrix = tensor of size batchsize x N x N\n",
    "\n",
    "    file, sigma_list, model_params = models[0]\n",
    "    model = load_model(*model_params)\n",
    "    sigma_tens = torch.linspace(0,1/2,noise_num)\n",
    "    sigma_list = sigma_tens.tolist()\n",
    "    sigma_list.sort()\n",
    "\n",
    "    def add_bernoulli(flags, init_adjs, noiselevel):\n",
    "        init_adjs, noise_added = discretenoise(init_adjs, flags, noiselevel, config)\n",
    "        return init_adjs\n",
    "\n",
    "\n",
    "    def take_step(noise_func, flags, init_adjs, noiselevel):\n",
    "        init_adjs = add_bernoulli(flags, init_adjs, noiselevel)\n",
    "        \n",
    "        mask=generate_mask(flags).to(config.dev)\n",
    "        noise_unnormal = noise_func(A=init_adjs.to(config.dev),feat=None,mask=mask.to(config.dev),noise=noiselevel)\n",
    "        noise_unnormal = noise_unnormal.squeeze(-1)\n",
    "        noise_rel = torch.sigmoid(noise_unnormal)\n",
    "        noise_rel = (noise_rel+noise_rel.transpose(-1,-2))/2\n",
    "        noise=torch.bernoulli(noise_rel)*mask\n",
    "        \n",
    "        inter_adjs = torch.where(noise>1/2,init_adjs-1,init_adjs)\n",
    "        new_adjs = torch.where(inter_adjs < -1/2 , inter_adjs+2 , inter_adjs)\n",
    "        \n",
    "        return init_adjs,new_adjs\n",
    "\n",
    "\n",
    "    def run_sample(eval_len=10, methods=None):\n",
    "        gen_graph_list = []\n",
    "        with torch.no_grad():\n",
    "            while len(gen_graph_list)<eval_len:\n",
    "                count=0\n",
    "                init_adjs, init_x, flags = gen_init_data(batch_size = test_batch_size)\n",
    "\n",
    "                ##\n",
    "                mult_stages_noise = []\n",
    "                mult_stages = [init_adjs.detach().cpu().numpy()]\n",
    "                mult_stages_flags = flags[-test_batch_size*(0+1): len(flags)-(test_batch_size*(0))]\n",
    "                ##\n",
    "\n",
    "                while count<len(sigma_list):\n",
    "                    noiselevel=sigma_list[len(sigma_list)-count-1]\n",
    "                    noisy_adjs,init_adjs=take_step(lambda feat, A, mask, noise: model(feat, A, mask, noise), flags=flags, init_adjs=init_adjs, noiselevel=noiselevel)\n",
    "                    count=count+1\n",
    "                    mult_stages_noise.append(noisy_adjs.detach().cpu().numpy())\n",
    "                    mult_stages.append(init_adjs.detach().cpu().numpy())\n",
    "                    mult_stages_flags = torch.cat((mult_stages_flags, flags[-test_batch_size*(count): len(flags)-(test_batch_size*(count-1))]),0)\n",
    "                gen_graph_list.extend(adjs_to_graphs(init_adjs.detach().cpu().numpy()))\n",
    "        enablePrint()\n",
    "        pic_title = f'{file.split(\"/\")[-1]}_final_sample_ipynb_{noise_num}.pdf'\n",
    "        #plot_graphs_list(graphs=gen_graph_list, title=pic_title, save_dir=config.save_dir)\n",
    "        plot_inter_graphs_jup(graphs=mult_stages, flags=mult_stages_flags, title='intermediate', save_dir=config.save_dir, nr_to_analyze=0)\n",
    "        plot_inter_graphs_jup(graphs=mult_stages_noise, flags=mult_stages_flags, title='intermediate', save_dir=config.save_dir, nr_to_analyze=0)\n",
    "        result_dict = eval_graph_list(test_graph_list, gen_graph_list, methods=methods)\n",
    "        return result_dict, gen_graph_list\n",
    "\n",
    "    result_dict, gen_graph_list = run_sample(eval_len=32)\n",
    "    return result_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d156f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all functions here used for sampling the ppgn vlb loss implementation\n",
    "\n",
    "def posterior(sigmatilde_t,sigma_t,sigmatilde_t1,x0,xt):\n",
    "    if xt<0.01 and x0<0.01:\n",
    "        return sigmatilde_t1 * sigma_t / (1-sigmatilde_t)\n",
    "    elif xt>0.99 and x0<0.01:\n",
    "        return sigmatilde_t1 * (1-sigma_t) / (sigmatilde_t)\n",
    "    elif xt>0.99 and x0>0.99:\n",
    "        return (1-sigmatilde_t1) * (1-sigma_t) / (1-sigmatilde_t)\n",
    "    if xt<0.01 and x0>0.99:\n",
    "        return (1-sigmatilde_t1) * sigma_t / (sigmatilde_t)\n",
    "\n",
    "def sigma_lin_false(sigma_list):\n",
    "    sigmas=[]\n",
    "    for g,sigma in enumerate(sigma_list):\n",
    "        if i<0.0000000001:\n",
    "            sigmas.append(0.0)\n",
    "        summ=0.0\n",
    "        for k,sigpast in enumerate(sigmas):\n",
    "            prod=1.0\n",
    "            for j in range(0,g-1-k):\n",
    "                prod = prod * ( 1 - 2 * sigmas[g-k] )\n",
    "            prod = prod * sigmas[k]\n",
    "        summ+=prod\n",
    "        s=sigma-summ\n",
    "        sigmas.append(s)\n",
    "\n",
    "def sigma_lin(sigma_list):\n",
    "    sigmas=[]\n",
    "    for g,sigma in enumerate(sigma_list):\n",
    "        if sigma<0.0000000001:\n",
    "            sigmas.append(0.0)\n",
    "            continue\n",
    "        sigmas.append(((1-sigma)-(1-sigma_list[g-1]))/(1-2*(1-sigma_list[g-1])))\n",
    "    return sigmas\n",
    "\n",
    "def sample_ppgn_vlb(config,modellink,noise_num):\n",
    "    start_time = time.time()\n",
    "    device=sys.stdout\n",
    "    blockPrint()\n",
    "    train_graph_list, test_graph_list = load_data(config, get_graph_list=True)\n",
    "    models = prepare_test_model_train(config,modellink)\n",
    "    max_node_number = config.dataset.max_node_num\n",
    "    test_batch_size = config.test.batch_size\n",
    "    test_batch_size = 1\n",
    "    \n",
    "    def gen_init_data(batch_size):\n",
    "        rand_idx = np.random.randint(0, len(train_graph_list), batch_size)\n",
    "        graph_list = [train_graph_list[i] for i in rand_idx]\n",
    "        base_adjs, base_x = graphs_to_tensor(config, graph_list)\n",
    "        base_adjs, base_x = base_adjs.to(config.dev), base_x.to(config.dev)\n",
    "        node_flags = base_adjs.sum(-1).gt(1e-5).to(dtype=torch.float32)\n",
    "\n",
    "        ##create a matrix with p=1/2 elements at all positions Aij where i and j not masked by node_flagij=0:\n",
    "        bernoulli_adj = torch.zeros(batch_size, max_node_number, max_node_number).to(config.dev)\n",
    "        for k, matrix in enumerate(base_adjs):\n",
    "            for i,row in enumerate(matrix):\n",
    "                    for j,col in enumerate(row):\n",
    "                        if 1/2 < node_flags[k][i] and 1/2 < node_flags[k][j]:\n",
    "                            bernoulli_adj[k,i,j] = 1/2\n",
    "        \n",
    "        noise_upper = torch.bernoulli(bernoulli_adj).triu(diagonal=1)\n",
    "        noise_lower = noise_upper.transpose(-1, -2)\n",
    "        initialmatrix = noise_lower + noise_upper\n",
    "        return initialmatrix, base_x, node_flags\n",
    "        ##returns initialmatrix = tensor of size batchsize x N x N\n",
    "\n",
    "    file, sigma_list, model_params = models[0]\n",
    "    model = load_model(*model_params)\n",
    "    sigma_tens = torch.linspace(0,1/2,noise_num+1)\n",
    "    sigma_list = sigma_tens.tolist()\n",
    "    sigma_list.sort()\n",
    "    sigma_list_nontilde=sigma_lin(sigma_list)\n",
    "\n",
    "    def add_bernoulli(flags, init_adjs, noiselevel):\n",
    "        init_adjs, noise_added = discretenoise(init_adjs, flags, noiselevel, config)\n",
    "        return init_adjs\n",
    "\n",
    "    def take_step(noise_func, flags, init_adjs, noiselevel,noiselevel_nontilde):\n",
    "        mask=generate_mask(flags).to(config.dev)\n",
    "        init_adjs = init_adjs * mask\n",
    "        noise_unnormal = noise_func(A=init_adjs.to(config.dev),feat=None,mask=mask.to(config.dev),noise=noiselevel).to(config.dev)\n",
    "        noise_unnormal = noise_unnormal.squeeze(-1)\n",
    "        noise_rel = torch.sigmoid(noise_unnormal)\n",
    "        noise_rel = (noise_rel+torch.transpose(noise_rel,-2,-1))/2\n",
    "        ##here now noise_rel = p(xo_switched | xt)\n",
    "        \n",
    "        sigmatilde_t=noiselevel\n",
    "        sigma_t=noiselevel_nontilde\n",
    "        sigmatilde_t1=sigmatilde_t-sigmatilde_t/sigma_list.index(sigmatilde_t)\n",
    "        score_i=torch.where(init_adjs>1/2,1-noise_rel,noise_rel)\n",
    "        \n",
    "        ##now calculate posterior(sigmatilde_t,sigma_t,sigmatilde_t1,0,xt)\n",
    "        mult1=torch.where(init_adjs>1/2,(1-sigma_t),sigma_t)\n",
    "        mult2=torch.where(torch.zeros_like(init_adjs)>1/2,1-sigmatilde_t1,sigmatilde_t1)\n",
    "        xor=torch.logical_xor(init_adjs, torch.zeros_like(init_adjs))\n",
    "        div=torch.where(xor>1/2,sigmatilde_t,1-sigmatilde_t)\n",
    "        p = ( 1 - score_i ) * mult1*mult2/div\n",
    "\n",
    "        ##now calculate posterior(sigmatilde_t,sigma_t,sigmatilde_t1,1,xt)\n",
    "        mult1=torch.where(init_adjs>1/2,(1-sigma_t),sigma_t)\n",
    "        mult2=torch.where(torch.ones_like(init_adjs)>1/2,1-sigmatilde_t1,sigmatilde_t1)\n",
    "        xor=torch.logical_xor(init_adjs, torch.ones_like(init_adjs))\n",
    "        div=torch.where(xor>1/2,sigmatilde_t,1-sigmatilde_t)\n",
    "        p += ( score_i ) * mult1 * mult2/div\n",
    "\n",
    "        ##p stands now for probablity p(x0=1|xt=xt)\n",
    "        init_adjs = (p + p.transpose(-2,-1))/2\n",
    "\n",
    "        ##now mask and sample from that and then make symmetrical, results in sample of x_0 given x_t\n",
    "        init_adjs = init_adjs * mask\n",
    "        init_adjs = torch.bernoulli(init_adjs).to(config.dev)\n",
    "        new_adjs=init_adjs\n",
    "        new_adjs = torch.triu(init_adjs,diagonal=1) + torch.triu(init_adjs,diagonal=1).transpose(-2,-1)\n",
    "        \n",
    "        return new_adjs\n",
    "\n",
    "\n",
    "    def run_sample(eval_len=10, methods=None):\n",
    "        gen_graph_list = []\n",
    "        with torch.no_grad():\n",
    "            while len(gen_graph_list)<eval_len:\n",
    "                count=0\n",
    "                init_adjs, init_x, flags = gen_init_data(batch_size = test_batch_size)\n",
    "\n",
    "                ###\n",
    "                mult_stages_noise = []\n",
    "                mult_stages = [init_adjs.detach().cpu().numpy()]\n",
    "                mult_stages_flags = flags[-test_batch_size*(0+1): len(flags)-(test_batch_size*(0))]\n",
    "                ###\n",
    "\n",
    "                while count<len(sigma_list)-1:\n",
    "                    noiselevel=sigma_list[len(sigma_list)-count-1]\n",
    "                    noiselevel_nontilde=sigma_list_nontilde[len(sigma_list)-count-1]\n",
    "                    init_adjs=take_step(lambda feat, A, mask, noise: model(feat, A, mask, noise), flags=flags, init_adjs=init_adjs, noiselevel=noiselevel,noiselevel_nontilde=noiselevel_nontilde)\n",
    "                    count=count+1\n",
    "                    \n",
    "                    mult_stages_noise.append(noisy_adjs.detach().cpu().numpy())\n",
    "                    mult_stages.append(init_adjs.detach().cpu().numpy())\n",
    "                    mult_stages_flags = torch.cat((mult_stages_flags, flags[-test_batch_size*(count): len(flags)-(test_batch_size*(count-1))]),0)\n",
    "                \n",
    "                gen_graph_list.extend(adjs_to_graphs(init_adjs.detach().cpu().numpy()))\n",
    "        enablePrint()\n",
    "        print(time.time()-start_time)\n",
    "        pic_title = f'{file.split(\"/\")[-1]}_final_sample_ipynb_{noise_num}.pdf'\n",
    "        #plot_graphs_list(graphs=gen_graph_list, title=pic_title, save_dir=config.save_dir)\n",
    "        plot_inter_graphs_jup(graphs=mult_stages, flags=mult_stages_flags, title='intermediate', save_dir=config.save_dir, nr_to_analyze=0)\n",
    "        result_dict = eval_graph_list(test_graph_list, gen_graph_list, methods=methods)\n",
    "        if \"sbm\" in config.dataset.name:\n",
    "            likelyhood = eval_acc_sbm_graph(gen_graph_list, p_intra=0.85, p_inter=0.046875,strict=False,is_parallel=False)\n",
    "            result_dict[\"likelyhood\"]=likelyhood\n",
    "        return result_dict, gen_graph_list, result_dict_2\n",
    "    \n",
    "    result_dict, gen_graph_list, result_dict_2 = run_sample(eval_len=32)\n",
    "    return result_dict, result_dict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Here testing is initiated \n",
    "\n",
    "## choose the corresponding trainrun and enter the config yaml file path here: (found in directory config/gridsearch/...)\n",
    "args = Namespace(config_file='config/gridsearch/consec_ppgn_1.7_17:42/gridsearch_ppgn_consec_ego_18_small_8,128_1_64_switched_True_1234.yaml', log_level='INFO', comment='')\n",
    "\n",
    "ori_config_dict = get_config(args)\n",
    "config_dict = edict(ori_config_dict.copy())\n",
    "process_config(config_dict)\n",
    "\n",
    "## depending on if you trained with ppgn_simple or ppgn_vlb run the correct sample function\n",
    "## choose the corresponding model you wish to test and enter its path here: (the directory to your model can easily be found in the info page of your wandb or in the .out file of your slurm_logs)\n",
    "## by using /best or /bestloss or /besloss_eval you may choose the models given by the modelselection instead of the most recent one\n",
    "## also choose what number of noiselevels you want to use (you may find it good to use more noiselevels for sampling than you did for training as the interval between two noiselevels is still somewhat well defined and informative and also in the ppgn_simple implementation we drew the levels randomly anyway and they werent fixxed on some number\n",
    "sample_ppgn_simple(config_dict,\"exp/gridsearch/ppgn_ego_18_small__Jul-01-17-42-58_155987/models\",32)\n",
    "##sample_ppgn_vlb(config_dict,\"/scratch/snx3000/khaefeli/khaefeli_graph_ddpm/GraphScoreMatching_ddpm_discrete/GraphScoreMatching_ppgn/exp/gridsearch/ppgn_ego_18_small__Jun-03-10-38-49_23391/models\",1,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067a6d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
